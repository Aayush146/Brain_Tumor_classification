# -*- coding: utf-8 -*-
"""AMLS_neural_net.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kZE44-7ApoHzComa08aeoHFZYuqSNRov
"""

!pip install pydicom
!pip install captum
!pip install -q tb-nightly

import os
import sklearn 
from sklearn.metrics import classification_report, recall_score
from sklearn.preprocessing import OneHotEncoder

# model interpretability 
import captum 
from PIL import Image
import requests
from io import BytesIO
import cv2 as cv

os.chdir('/content/drive/MyDrive/AMLS_2/Assignment')
import amls_dataset_loader
from amls_dataset_loader import *

from torchsummary import summary

# create the pipeline 
base_path_x = '/content/drive/MyDrive/AMLS_2/Assignment/Dataset/train/'
base_path_y = '/content/drive/MyDrive/AMLS_2/Assignment/Dataset/train_labels.csv'
batch_size = 25

train_dataset = Train_data(base_path_x, base_path_y, 'FLAIR', 'T2w', 0.7)
train_dict = train_dataset.get_dict()

Validation_set = dataset_2(base_path_x, base_path_y, 'FLAIR', 'T2w', train_dict, 0.5, False)
validation_dict = Validation_set.get_dict()

test_dict = {**train_dict ,**validation_dict}
test_data = dataset_2(base_path_x, base_path_y,'FLAIR', 'T2w', test_dict, 0.5, True)

dataset_loader_train = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = False)
dataset_validation = torch.utils.data.DataLoader(Validation_set, batch_size = batch_size, shuffle = False)
dataset_loader_test = torch.utils.data.DataLoader(test_data, batch_size = batch_size, shuffle = False)

"""## CRNN"""

class CRNNnet1(nn.Module):

  def __init__(self,seq_length,n_channels):
      super().__init__()

      self.seq_length = int(seq_length)
      self.n_channels = int(n_channels)
      self.num_classes = 2
      self.hidden_size = 64
      self.input_size = 5
      self.conv1 = nn.Conv2d(self.n_channels, 4 * self.seq_length, 10,1) # (input channel, number of filters,  kernel size , stride)
      self.dropout_1 = nn.Dropout(0.25)
      self.rnn= nn.GRU(
          input_size = self.input_size * self.seq_length *500, 
          hidden_size = self.hidden_size, 
          num_layers = 1, 
          batch_first = True, 
          bidirectional = True)
      self.linear = nn.Linear(128, self.num_classes)
      

  def forward(self, x):

      # first convolution layer 
      x = F.relu(self.conv1(x))
      x = F.max_pool2d(x, 4)
      x = torch.flatten(x[0])
      x= x.view(25,self.seq_length, 2500)
      x, (h_n) = self.rnn(x)
      x = self.linear(x[:, -1, :])
      output = torch.sigmoid(x)
      output = output.view((25,2,1))
  
      return output

net_1 = CRNNnet1(seq_length = 1, n_channels = 2)

class CRNNnet2(nn.Module):

  def __init__(self,seq_length,n_channels):
      super().__init__()

      self.seq_length = int(seq_length)
      self.n_channels = int(n_channels)
      self.num_classes = 2
      self.hidden_size = 64
      self.input_size = 3
      self.conv1 = nn.Conv2d(self.n_channels, 3 * self.seq_length, 10,1) # (input channel, number of filters,  kernel size , stride)
      self.conv2 = nn.Conv2d(self.input_size*2*self.seq_length,3 * self.seq_length,5, 1)
      self.dropout_1 = nn.Dropout(0.25)
      self.dropout_2 = nn.Dropout(0.25)
      self.rnn= nn.GRU(
          input_size = self.input_size * self.seq_length *144,
          hidden_size = self.hidden_size, 
          num_layers = 1, 
          batch_first = True, 
          bidirectional = True)
      self.linear = nn.Linear(128, self.num_classes)
      

  def forward(self, x):

      # first convolution layer 
      x = F.relu(self.conv1(x))
      x = F.max_pool2d(x, 2)
      
      # second convolution layer
      x = F.relu(self.conv2(x))
      x = F.max_pool2d(x, 2)
      x = self.dropout_1(x)
      x = torch.flatten(x[0])
      x= x.view(25,self.seq_length, -1)
      x, (h_n) = self.rnn(x)
      x = self.linear(x[:, -1, :])
      output = torch.sigmoid(x)
      output = output.view((25,2,1))
  
      return output

net_2 = CRNNnet2(seq_length = 1, n_channels = 2)

# random custom model 
class CRNNnet3(nn.Module):

  def __init__(self,seq_length,n_channels):
      super().__init__()

      self.seq_length = int(seq_length)
      self.n_channels = int(n_channels)
      self.num_classes = 2
      self.hidden_size = 64
      self.input_size = 2
      self.conv1 = nn.Conv2d(self.n_channels, 6 * self.seq_length, 10,1) # (input channel, number of filters,  kernel size , stride)
      self.conv2 = nn.Conv2d(6*self.seq_length,3 * self.seq_length,5, 1)
      self.conv3 = nn.Conv2d(3*self.seq_length, self.seq_length, 3,1)
      self.dropout_1 = nn.Dropout(0.25)
      self.dropout_2 = nn.Dropout(0.25)
      self.dropout_3 = nn.Dropout(0.25)
      self.rnn= nn.GRU(
          input_size = self.seq_length *144,
          hidden_size = self.hidden_size, 
          num_layers = 1, 
          batch_first = True, 
          bidirectional = True)
      self.linear = nn.Linear(128, self.num_classes)
      

  def forward(self, x):

      # first convolution layer 
      x = F.relu(self.conv1(x))
      x = F.max_pool2d(x, 2)
      # second convolution layer
      x = F.relu(self.conv2(x))
      x = F.max_pool2d(x, 2)
      x = self.dropout_1(x)
      # third convolution layer
      x = F.relu(self.conv3(x))
      x = F.max_pool2d(x, 2)
      x = self.dropout_3(x)
      x = torch.flatten(x[0])
      x= x.view(25,self.seq_length, -1)
      x, (h_n) = self.rnn(x)
      x = self.linear(x[:, -1, :])
      output = torch.sigmoid(x)
      output = output.view((25,2,1))
  
      return output

"""## K fold GridsearchCV"""

learning_rates = [0.001,0.01,0.1] # learning rates list 
momentum = [0.9,0.95, 0.99] # momentum list 
net = CRNNnet3(seq_length = 1, n_channels = 2)
cv_splits = 5 
kfold = KFold(n_splits=cv_splits, shuffle=True, random_state=42) # create a K splits object 

results = [] # results list

hyper_params = list(product(learning_rates, momentum)) # get different cobinations of learning rate and momentum values 
device = torch.device('cuda:0')
net = net.to(device)

# loop over the hyperparameter combinations  we want to apply 

for lr, moments in hyper_params:

  criterion = nn.BCELoss()
  optimizer = optim.SGD(net.parameters(), lr= lr, momentum = moments)
  
  fold_results = {'leanring_rate': lr, 'momentum' : moments , 'accuracy': [], 'val_loss': []}

  for train_idx, val_idx in kfold.split(Validation_set):
     
    # get a training fold for training on yuor model
    train_sampler = SubsetRandomSampler(train_idx)
    # get the test/validation fold for testing your model 
    vali_sampler = SubsetRandomSampler(val_idx)

  # Create DataLoaders for both set
    train_loader = DataLoader(Validation_set, batch_size= 25, shuffle = False, sampler = train_sampler)
    vali_loader = DataLoader(Validation_set, batch_size = 25, shuffle = False, sampler = vali_sampler)

    # put the network in trianing mode as we have nomalization layers 
    net.train()
    for epoch in range(10):
      
      for inputs, targets in train_loader:
        
        inputs = inputs.to(device)
        targets = targets.to(device)
        optimizer.zero_grad()
        outputs = net(inputs)

        loss = criterion(outputs.float(), targets.float())
        loss.backward()
        optimizer.step()

    correct = 0
    total = 0.0
    val_loss = 0.0

    # put the netowkr in evaluation mode to change the state of the batchNormalization layers
    net.eval()

    for batch, (inputs, targets) in enumerate(vali_loader):

      inputs = inputs.to(device)
      targets = targets.to(device)
      outputs = net(inputs)
      total += targets.size(0)
      correct += (outputs.round() == targets).float().mean()
      loss = criterion(outputs.float(), targets.float())
      val_loss += loss.item()
      torch.cuda.empty_cache()

    accuracy = 100 * correct/len(vali_loader)
    fold_results['val_loss'].append(val_loss)
    fold_results['accuracy'].append(accuracy)
     
  fold_results['val_loss'] = sum(fold_results['val_loss']) / len(fold_results['val_loss'])
  fold_results['accuracy'] = sum(fold_results['accuracy']) / len(fold_results['accuracy'])
  results.append(fold_results)

results[4]

"""## Convolution layer optimzation """

cv_splits = 5 
kfold = KFold(n_splits=cv_splits, shuffle=True, random_state=3) # create a K splits object 
device = torch.device('cuda:0')
net_2 = net_2.to(device)
results = [] # results list
criterion = nn.BCELoss()
optimizer = optim.SGD(net_1.parameters(), lr= 0.01, momentum = 0.99)


for train_idx, val_idx in kfold.split(Validation_set):
     
    # get a training fold for training on yuor model
    train_sampler = SubsetRandomSampler(train_idx)
    # get the test/validation fold for testing your model 
    vali_sampler = SubsetRandomSampler(val_idx)

    fold_result = []

  # Create DataLoaders for both set
    train_loader = DataLoader(Validation_set, batch_size= 25, shuffle = False, sampler = train_sampler)
    vali_loader = DataLoader(Validation_set, batch_size = 25, shuffle = False, sampler = vali_sampler)

    # put the network in trianing mode as we have nomalization layers 
    net_2.train()
    for epoch in range(10):
      
      for inputs, targets in train_loader:
        
        inputs = inputs.to(device)
        targets = targets.to(device)
        optimizer.zero_grad()
        outputs = net_2(inputs)

        loss = criterion(outputs.float(), targets.float())
        loss.backward()
        optimizer.step()

    correct = 0
    total = 0.0
    val_loss = 0.0

    # put the netowkr in evaluation mode to change the state of the batchNormalization layers
    net_2.eval()

    for batch, (inputs, targets) in enumerate(vali_loader):

      inputs = inputs.to(device)
      targets = targets.to(device)
      outputs = net_2(inputs)
      total += targets.size(0)
      correct += (outputs.round() == targets).float().mean()
      loss = criterion(outputs.float(), targets.float())
      val_loss += loss.item()
      torch.cuda.empty_cache()
      
      accuracy = 100 * correct/len(vali_loader)
      fold_result.append(accuracy)

    res = sum(fold_result)/len(fold_result)
    results.append(res)

print(results)

"""### CRNN training on final model """

final_net_1 = CRNNnet3(seq_length = 1, n_channels = 2)
epochs = 45
criterion = nn.BCELoss()
optimizer_1 = optim.SGD(final_net_1.parameters(), lr= 0.01, momentum = 0.99)
if torch.cuda.is_available():
  device = torch.device('cuda:0')
  final_net_1 = final_net_1.to(device)

train_accuracy_list = []
val_accuracy_list = []
train_loss = []
val_loss = []

writer = SummaryWriter('logs')
for epoch in range(epochs):

  train_run_loss = 0.0
  train_run_accu = 0.0
  val_run_loss = 0.0
  val_run_accu = 0.0

  # maybe add a variable that can be used to train the model 

  final_net_1.train()
  for data in dataset_loader_train:

    # input and output label batches 
    (inputs, labels, clas_name) = data
    inputs = inputs.to(device)
    labels = labels.to(device)

    # make the gradients zero to avoid previous step gradients to be used
    optimizer_1.zero_grad()

    #calcualte the output
    outputs = final_net_1(inputs)

    # calcualte the loss
    try:
      loss = criterion(outputs.float(), labels.float())
    except Exception as e:
      continue 
    
    # back propagate the loss
    loss.backward()

    # add gradints to a log 

    for name, param in final_net_1.named_parameters():
      writer.add_histogram(name + '/grad', param.grad, epoch)

    # update the model weights 
    optimizer_1.step()

    # update runnning loss 
    train_run_loss += loss.item()

    # update running accuracy
    
    train_run_accu += (outputs.round() == labels).float().mean()

    del inputs, labels, outputs
    torch.cuda.empty_cache()
  
  final_net_1.eval()
  with torch.no_grad():
    for val_input, val_labels, mod_1_path in dataset_validation:

      val_input = val_input.to(device)
      val_labels = val_labels.to(device)

      val_outputs = final_net_1(val_input)

      loss_v = criterion(val_outputs.float(), val_labels.float()) # the items need to be a float for the loss function to be computed effectively

      # update runnning loss 
      val_run_loss += loss_v.item()
    
      # update running accuracy
      val_run_accu += (val_outputs.round() == val_labels).float().mean()
    
    # Calculate Training loss 
    train_epoch_loss = train_run_loss/len(dataset_loader_train) 
    train_loss.append(train_epoch_loss)

    # Calculate Training Accuracy
    epoch_acc = train_run_accu/ len(dataset_loader_train)  
    train_accuracy_list.append(epoch_acc)

    # Calculate validation loss
    val_epoch_loss = val_run_loss/len(dataset_validation) 
    val_loss.append(val_epoch_loss)

    # Calculate validation accuracy
    val_epoch_acc = val_run_accu/ len(dataset_validation) 
    val_accuracy_list.append(val_epoch_acc)

    writer.add_scalar('Training_Loss', train_epoch_loss, epoch)
    writer.add_scalar('Training_Accuracy', epoch_acc *100, epoch)

    writer.add_scalar('Validation_loss', val_epoch_loss, epoch)
    writer.add_scalar('Validation_accuracy', val_epoch_acc, epoch)

    # Priniting the epoch, loss and accuracy
    print('epoch : {}, training loss : {}, training accuracy : {}%'.format(epoch, train_epoch_loss, epoch_acc*100))
    print('epoch : {}, val_loss : {}, val_accuracy : {}% '.format(epoch, val_epoch_loss,val_epoch_acc*100))
    print()

training_accuracy = [i.data.cpu().numpy() * 100 for i in train_accuracy_list]
val_accuracy = [i.data.cpu().numpy() * 100 for i in val_accuracy_list]
vali_loss = [i for i in val_loss]
train_looos = [i for i in train_loss]
plt.figure(figsize = (20,8))
# plt.title(' Tracking acccuracy over epochs', fontsize = 25)
pochs = [i for i in range(1, epochs+1)]
plt.plot(pochs,training_accuracy, label = 'Training accuracy')
plt.plot(pochs, val_accuracy, label = 'Validation accuracy')
plt.xlabel('Epochs', fontsize = 20)
plt.ylabel('Accuracy %' , fontsize = 20)
plt.legend()

plt.figure(figsize = (20,8))
# plt.title(' Tracking acccuracy over epochs', fontsize = 25)
pochs = [i for i in range(1, epochs+1)]
plt.plot(pochs, vali_loss, label = 'Validation loss')
plt.plot(pochs, train_looos, label = 'Training loss')
plt.xlabel('Epochs', fontsize = 20)
plt.ylabel('Loss' , fontsize = 20)
plt.legend()

model_path = "/content/drive/MyDrive/AMLS_2/Assignment/model_state_dicts/final_model_3.pt"
torch.save(final_net_1.state_dict(), model_path)

"""## Model Interpretability"""

# load the saved model 
device = torch.device('cuda')
model_1 = CRNNnet3(seq_length = 1, n_channels = 2)
model_1.load_state_dict(torch.load('/content/drive/MyDrive/AMLS_2/Assignment/model_state_dicts/final_model_3.pt'))
model = model_1.to(device)

from captum.attr import Occlusion
from captum.attr import IntegratedGradients
from captum.attr import Saliency
from captum.attr import visualization as viz

neum = enumerate(dataset_loader_test)

for batch, (inputs, target, mod_1_path) in enumerate(dataset_loader_test):

  print(mod_1_path)

  inputs = inputs.to(device)
  target = target.to(device)

  ig = IntegratedGradients(model_1)
  attribution = ig.attribute(inputs, target= 1, n_steps = 1, internal_batch_size = 25)

  input_index = 0  # Example for the first input in the batch
  attribution_single = attribution[input_index]  # Get the attributions for the input
  input_single = inputs[input_index]  # Get the input

  # Reshape the attribution scores to match the input shape (3, 224, 224)
  attribution_single = attribution_single.reshape(input_single.shape)

  # Normalize the attribution scores
  attribution_single /= torch.max(torch.abs(attribution_single))

  # Create a heatmap of the attribution scores
  heatmap = plt.imshow(attribution_single[0].cpu(), cmap='bwr', alpha=0.8)

  # Overlay the heatmap on top of the input image
  plt.imshow(input_single.permute(0,2,1).cpu()[1,:,:].numpy())
  plt.colorbar(heatmap)
  plt.axis('off')
  plt.show()

  break

"""## Model Testing"""

model.eval()
with torch.no_grad():
  
  test_preds = None
  test_labs = None

  for test_data in dataset_loader_test:

    test_inputs, test_labels, mod_1_path  = test_data
    test_inputs= test_inputs.to(device)
    test_labels  = test_labels.to(device)


    test_outputs = model_1(test_inputs)
    test_outputs = test_outputs.cpu().round().int()
    test_outputs = test_outputs.numpy()
    test_outputs = np.argmax(test_outputs, axis = 1)
  
    # # update running accuracy
    test_preds = test_outputs
  
    test_labels = test_labels.cpu().numpy()
    test_labels = np.argmax(test_labels, axis = 1)
    test_labs = test_labels

test_preds = np.array(test_preds)
test_labels = np.array(test_labs)
gm = classification_report(test_labels, test_preds)

print(gm)